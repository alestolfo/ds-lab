{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional density estimation with noise regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/camillca/anaconda3/envs/dslab/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from utils import create_dataset_mri, cv_for_cde, create_dataset_eeg\n",
    "from cde.density_estimator import MixtureDensityNetwork\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.python.keras.activations import tanh\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# torch version\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "target = 'Age'\n",
    "# use all MRI high-level features, no DTI\n",
    "data = create_dataset_mri(SCORE = target)\n",
    "# for the moment, remove the diagnosis colums\n",
    "data.drop(columns=['DX_01_Cat', 'DX_01_Sub', 'DX_01'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = pd.read_csv('data/test_IDS.csv')\n",
    "# Separate test and train set\n",
    "data_test = pd.merge(data, test_indices, on='ID', how='inner')\n",
    "data_train = data.loc[~data['ID'].isin(list((set(test_indices['ID']))))]\n",
    "# labels and features\n",
    "y_train = data_train[target]\n",
    "X_train = data_train.drop([target, 'ID'], axis=1)\n",
    "y_test = data_test[target]\n",
    "X_test = data_test.drop([target, 'ID'], axis=1)\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_train = np.array(X_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train.reshape((-1,1))\n",
    "y_test = y_test.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0.9814850749319165\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 11s | loss: 1500.004\n",
      "mean log-loss train: 1.4620\n",
      "Test MSE: 5.612370445606043\n"
     ]
    }
   ],
   "source": [
    "# Set model parameters\n",
    "ndim_x=X_train.shape[1]\n",
    "ndim_y=y_train.shape[1]\n",
    "# We try the \"faster decay rate for non-gaussian data\" proposed in the paper: h = n^(-1/(d+1))\n",
    "n = X_train.shape[0]\n",
    "d = X_train.shape[1]+y_train.shape[1]\n",
    "h = n**(-1/(d+1))\n",
    "\n",
    "print('h = {}'.format(h))\n",
    "\n",
    "# Define the model\n",
    "model = MixtureDensityNetwork('MDN_mri', ndim_x, ndim_y, n_centers=10, hidden_sizes=(16, 16), hidden_nonlinearity=tf.nn.tanh,\n",
    "               n_training_epochs=1000, x_noise_std=h, y_noise_std=h, adaptive_noise_fn=None, entropy_reg_coef=0.0,\n",
    "               weight_decay=0.0, weight_normalization=True, data_normalization=True, dropout=0.0, l2_reg=0.0, l1_reg=0.0,\n",
    "               random_seed=42)\n",
    "# Fit\n",
    "model.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = model.mean_(X_test)\n",
    "y_pred = y_pred.reshape((-1,1))\n",
    "y_pred.shape\n",
    "print('Test MSE: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 11s | loss: 1190.518\n",
      "mean log-loss train: 1.4519\n",
      "MSE: 5.463922072129362\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 11s | loss: 1210.741\n",
      "mean log-loss train: 1.4747\n",
      "MSE: 5.0702302959467325\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 11s | loss: 1192.160\n",
      "mean log-loss train: 1.4521\n",
      "MSE: 4.651610983115361\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 12s | loss: 1204.898\n",
      "mean log-loss train: 1.4676\n",
      "MSE: 5.1260233999718965\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 12s | loss: 1217.456\n",
      "mean log-loss train: 1.4829\n",
      "MSE: 5.625973580891862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.187552066411043"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV results\n",
    "res = cv_for_cde(X_train, y_train.flatten(), 'mri', h, n_splits=5)\n",
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same, without noise regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural MRI + DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "target = 'Age'\n",
    "# use all MRI high-level features, plus DTI\n",
    "data = create_dataset_mri(SCORE = target, DTI = True)\n",
    "# for the moment, remove the diagnosis colums\n",
    "data.drop(columns=['DX_01_Cat', 'DX_01_Sub', 'DX_01'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = pd.read_csv('data/test_IDS.csv')\n",
    "# Separate test and train set\n",
    "data_test = pd.merge(data, test_indices, on='ID', how='inner')\n",
    "data_train = data.loc[~data['ID'].isin(list((set(test_indices['ID']))))]\n",
    "# labels and features\n",
    "y_train = data_train[target]\n",
    "X_train = data_train.drop([target, 'ID'], axis=1)\n",
    "y_test = data_test[target]\n",
    "X_test = data_test.drop([target, 'ID'], axis=1)\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_train = np.array(X_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train.reshape((-1,1))\n",
    "y_test = y_test.reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing DTI values\n",
    "imp = SimpleImputer(strategy = 'median')\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 14s | loss: 1037.765\n",
      "mean log-loss train: 1.4454\n",
      "Test MSE: 5.858093329987868\n"
     ]
    }
   ],
   "source": [
    "# Set model parameters\n",
    "ndim_x=X_train.shape[1]\n",
    "ndim_y=y_train.shape[1]\n",
    "# We try the \"faster decay rate for non-gaussian data\" proposed in the paper: h = n^(-1/(d+1))\n",
    "n = X_train.shape[0]\n",
    "d = X_train.shape[1]+y_train.shape[1]\n",
    "h = n**(-1/(d+1))\n",
    "# Define the model\n",
    "model = MixtureDensityNetwork('MDN_dti', ndim_x, ndim_y, n_centers=10, hidden_sizes=(16, 16), hidden_nonlinearity=tf.nn.tanh,\n",
    "               n_training_epochs=1000, x_noise_std=h, y_noise_std=h, adaptive_noise_fn=None, entropy_reg_coef=0.0,\n",
    "               weight_decay=0.0, weight_normalization=True, data_normalization=True, dropout=0.0, l2_reg=0.0, l1_reg=0.0,\n",
    "               random_seed=42)\n",
    "# Fit\n",
    "model.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = model.mean_(X_test)\n",
    "y_pred = y_pred.reshape((-1,1))\n",
    "y_pred.shape\n",
    "print('Test MSE: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 13s | loss: 848.138\n",
      "mean log-loss train: 1.4776\n",
      "MSE: 5.405847079573783\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 13s | loss: 838.366\n",
      "mean log-loss train: 1.4606\n",
      "MSE: 5.960919393053572\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 13s | loss: 868.571\n",
      "mean log-loss train: 1.5132\n",
      "MSE: 4.763439354759247\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 15s | loss: 840.152\n",
      "mean log-loss train: 1.4611\n",
      "MSE: 4.8010148320364685\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 15s | loss: 856.639\n",
      "mean log-loss train: 1.4898\n",
      "MSE: 4.645745340876976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.1153932000600095"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV results\n",
    "res = cv_for_cde(X_train, y_train.flatten(), 'dti', h, n_splits=5)\n",
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "target = 'Age'\n",
    "# eeg cluster features\n",
    "data = create_dataset_eeg(SCORE = target, clusters = True)\n",
    "# for the moment, remove the diagnosis colums\n",
    "data.drop(columns=['DX_01_Cat', 'DX_01_Sub', 'DX_01'], inplace=True)\n",
    "data.rename(columns={\"id\": \"ID\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = pd.read_csv('data/test_IDS.csv')\n",
    "# Separate test and train set\n",
    "data_test = pd.merge(data, test_indices, on='ID', how='inner')\n",
    "data_train = data.loc[~data['ID'].isin(list((set(test_indices['ID']))))]\n",
    "# labels and features\n",
    "y_train = data_train[target]\n",
    "X_train = data_train.drop([target, 'ID'], axis=1)\n",
    "y_test = data_test[target]\n",
    "X_test = data_test.drop([target, 'ID'], axis=1)\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_train = np.array(X_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train.reshape((-1,1))\n",
    "y_test = y_test.reshape((-1,1))\n",
    "\n",
    "# Impute missing values\n",
    "imp = SimpleImputer(strategy = 'median')\n",
    "X_train = imp.fit_transform(X_train)\n",
    "X_test = imp.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0.9768343244122416\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 18s | loss: 1829.123\n",
      "mean log-loss train: 1.5423\n",
      "Test MSE: 6.244518418716428\n"
     ]
    }
   ],
   "source": [
    "# Set model parameters\n",
    "ndim_x=X_train.shape[1]\n",
    "ndim_y=y_train.shape[1]\n",
    "# We try the \"faster decay rate for non-gaussian data\" proposed in the paper: h = n^(-1/(d+1))\n",
    "n = X_train.shape[0]\n",
    "d = X_train.shape[1]+y_train.shape[1]\n",
    "h = n**(-1/(d+1))\n",
    "print('h = {}'.format(h))\n",
    "# Define the model\n",
    "model = MixtureDensityNetwork('MDN_eeg', ndim_x, ndim_y, n_centers=10, hidden_sizes=(16, 16), hidden_nonlinearity=tf.nn.tanh,\n",
    "               n_training_epochs=1000, x_noise_std=h, y_noise_std=h, adaptive_noise_fn=None, entropy_reg_coef=0.0,\n",
    "               weight_decay=0.0, weight_normalization=True, data_normalization=True, dropout=0.0, l2_reg=0.0, l1_reg=0.0,\n",
    "               random_seed=42)\n",
    "# Fit\n",
    "model.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = model.mean_(X_test)\n",
    "y_pred = y_pred.reshape((-1,1))\n",
    "y_pred.shape\n",
    "print('Test MSE: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 17s | loss: 1423.387\n",
      "mean log-loss train: 1.5015\n",
      "MSE: 6.639125967481024\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 18s | loss: 1407.995\n",
      "mean log-loss train: 1.4837\n",
      "MSE: 5.6885191118183736\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 19s | loss: 1472.065\n",
      "mean log-loss train: 1.5512\n",
      "MSE: 5.583397366047567\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 21s | loss: 1492.313\n",
      "mean log-loss train: 1.5725\n",
      "MSE: 5.173750931694996\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 21s | loss: 1450.329\n",
      "mean log-loss train: 1.5283\n",
      "MSE: 6.13996843113422\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.844952361635237"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV results\n",
    "res = cv_for_cde(X_train, y_train.flatten(), 'eeg', h, n_splits=5)\n",
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see EEG with na removed rather than imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "target = 'Age'\n",
    "# eeg cluster features\n",
    "data = create_dataset_eeg(SCORE = target, clusters = True)\n",
    "# for the moment, remove the diagnosis colums\n",
    "data.drop(columns=['DX_01_Cat', 'DX_01_Sub', 'DX_01'], inplace=True)\n",
    "data.rename(columns={\"id\": \"ID\"}, inplace=True)\n",
    "data.dropna(axis  =0, inplace=True)\n",
    "test_indices = pd.read_csv('data/test_IDS.csv')\n",
    "# Separate test and train set\n",
    "data_test = pd.merge(data, test_indices, on='ID', how='inner')\n",
    "data_train = data.loc[~data['ID'].isin(list((set(test_indices['ID']))))]\n",
    "# labels and features\n",
    "y_train = data_train[target]\n",
    "X_train = data_train.drop([target, 'ID'], axis=1)\n",
    "y_test = data_test[target]\n",
    "X_test = data_test.drop([target, 'ID'], axis=1)\n",
    "\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_train = np.array(X_train)\n",
    "y_test = np.array(y_test)\n",
    "y_train = np.array(y_train)\n",
    "y_train = y_train.reshape((-1,1))\n",
    "y_test = y_test.reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h = 0.9787417767039791\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 22s | loss: 981.143\n",
      "mean log-loss train: 1.4911\n",
      "Test MSE: 7.931212357043834\n"
     ]
    }
   ],
   "source": [
    "# Set model parameters\n",
    "ndim_x=X_train.shape[1]\n",
    "ndim_y=y_train.shape[1]\n",
    "# We try the \"faster decay rate for non-gaussian data\" proposed in the paper: h = n^(-1/(d+1))\n",
    "n = X_train.shape[0]\n",
    "d = X_train.shape[1]+y_train.shape[1]\n",
    "h = n**(-1/(d+1))\n",
    "print('h = {}'.format(h))\n",
    "# Define the model\n",
    "model = MixtureDensityNetwork('MDN_eeg_2', ndim_x, ndim_y, n_centers=10, hidden_sizes=(16, 16), hidden_nonlinearity=tf.nn.tanh,\n",
    "               n_training_epochs=1000, x_noise_std=h, y_noise_std=h, adaptive_noise_fn=None, entropy_reg_coef=0.0,\n",
    "               weight_decay=0.0, weight_normalization=True, data_normalization=True, dropout=0.0, l2_reg=0.0, l1_reg=0.0,\n",
    "               random_seed=42)\n",
    "# Fit\n",
    "model.fit(X_train, y_train)\n",
    "# Predict\n",
    "y_pred = model.mean_(X_test)\n",
    "y_pred = y_pred.reshape((-1,1))\n",
    "y_pred.shape\n",
    "print('Test MSE: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 24s | loss: 804.114\n",
      "mean log-loss train: 1.5287\n",
      "MSE: 4.805054557384899\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 24s | loss: 774.457\n",
      "mean log-loss train: 1.4724\n",
      "MSE: 6.072229746826974\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 26s | loss: 754.245\n",
      "mean log-loss train: 1.4339\n",
      "MSE: 6.048366685498241\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 27s | loss: 790.847\n",
      "mean log-loss train: 1.5007\n",
      "MSE: 6.1304244009061994\n",
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 30s | loss: 791.639\n",
      "mean log-loss train: 1.5022\n",
      "MSE: 5.654705608081803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.7421561997396235"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV results\n",
    "res = cv_for_cde(X_train, y_train.flatten(), 'eeg_2', h, n_splits=5)\n",
    "np.mean(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not necessary to scale the input data (the model already does normalization).\n",
    "Note that with DTI we obtain results similar to pure MRI. EEG data gives the worst results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dslab",
   "language": "python",
   "name": "dslab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
