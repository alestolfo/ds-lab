{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age prediction from MRI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import visualize, create_dataset_age, create_dataset_mri, cv\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Age'\n",
    "# use all MRI high-level features, no DTI\n",
    "data = create_dataset_mri(SCORE = target)\n",
    "# for the moment, remove the diagnosis colums\n",
    "try:\n",
    "    data.drop(columns=['DX_01_Cat'], inplace=True)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    data.drop(columns=['DX_01_Sub'], inplace=True)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    data.drop(columns=['DX_01'], inplace=True)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with some NaNs\n",
    "# print(data.shape)\n",
    "# data.dropna(axis=0, inplace=True)\n",
    "# print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels and features\n",
    "y = data[target]\n",
    "X = data.drop([target, 'ID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix a baseline (mean age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_age = 10.719744772251309\n",
      "baseline_MSE = 13.723839851203406\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "mean = np.mean(y)\n",
    "print('mean_age = {}'.format(mean))\n",
    "baseline_MSE = sum((mean - y)**2)/len(y)\n",
    "print('baseline_MSE = {}'.format(baseline_MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore different regressors and feature selection procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR with no feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   27.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 40.86264295031016\n",
      "Selected hyperparameters: {'regression__C': 1, 'regression__epsilon': 0.1, 'regression__kernel': 'poly'}\n",
      "Split: 6\n",
      "Average expected test MSE: 43.25064774716446\n",
      "True test error: 17.239127508259834\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('regression', SVR())])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'regression__C' : [0.2, 0.3, 0.5, 0.8, 1],\n",
    "            'regression__epsilon' : [0.05, 0.1, 0.3, 0.5, 0.7],\n",
    "            'regression__kernel' : ['rbf', 'poly']}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectKBest + SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   36.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 7.625894965403726\n",
      "Selected hyperparameters: {'feat_select__k': 10, 'feat_select__score_func': <function f_regression at 0x7fb656a33730>, 'regression__C': 0.8, 'regression__epsilon': 0.1, 'regression__kernel': 'rbf'}\n",
      "Split: 1\r",
      "Split: 2\r",
      "Split: 3\r",
      "Split: 4\r",
      "Split: 5\r\n",
      "Average expected test MSE: 7.625894965403726\n",
      "True test error: 7.719118076865477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  1.6min finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectKBest()),\n",
    "  ('regression', SVR())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'regression__C' : [0.5, 0.8],\n",
    "            'regression__epsilon' : [0.05, 0.1, 0.3, 0.5],\n",
    "            'regression__kernel' : ['rbf'],\n",
    "            'feat_select__score_func' : [f_regression, mutual_info_regression],\n",
    "            'feat_select__k' : [10, 20, 40, 80, 95]}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 375 candidates, totalling 1875 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1875 out of 1875 | elapsed: 25.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 7.304901016006843\n",
      "Selected hyperparameters: {'feat_select__estimator__n_estimators': 130, 'feat_select__max_features': 10, 'feat_select__threshold': -inf, 'regression__C': 1.5, 'regression__epsilon': 0.1, 'regression__kernel': 'rbf'}\n",
      "Split: 5\n",
      "Average expected test MSE: 6.959375581824299\n",
      "True test error: 7.75742927858555\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor(100))),\n",
    "  ('regression', SVR())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'regression__C' : [0.3, 0.5, 0.8, 1, 1.5],\n",
    "            'regression__epsilon' : [0.01, 0.05, 0.1, 0.3, 0.5],\n",
    "            'regression__kernel' : ['rbf'],\n",
    "            'feat_select__estimator__n_estimators' : [100, 130, 180],\n",
    "            'feat_select__threshold' : [-np.inf],\n",
    "            'feat_select__max_features' : [10, 20, 40, 140, 230]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 960 candidates, totalling 4800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed: 16.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 19.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4026 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4800 out of 4800 | elapsed: 26.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 8.459687844612185\n",
      "Selected hyperparameters: {'feat_select__estimator__min_samples_leaf': 1, 'feat_select__estimator__n_estimators': 100, 'feat_select__max_features': 40, 'feat_select__threshold': -inf, 'regression__max_depth': 2, 'regression__min_samples_leaf': 8}\n",
      "Split: 5\n",
      "Average expected test MSE: 7.966993533796078\n",
      "True test error: 8.200068968458565\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor())),\n",
    "  ('regression', RandomForestRegressor())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'feat_select__estimator__n_estimators' : [50, 80, 100],\n",
    "              'feat_select__estimator__min_samples_leaf' : [1, 2, 5, 8],\n",
    "            'feat_select__threshold' : [-np.inf],\n",
    "            'feat_select__max_features' : [40, 140, 180, 200, 230],\n",
    "            'regression__max_depth' : [2, 3, 6, 12],\n",
    "            'regression__min_samples_leaf' : [1, 3, 5, 8]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:  5.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:17:55] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean cross-validated score of the best estimator: 7.699949371158411\n",
      "Selected hyperparameters: {'feat_select__estimator__min_samples_leaf': 4, 'feat_select__estimator__n_estimators': 100, 'feat_select__max_features': 10, 'feat_select__threshold': -inf, 'regression__booster__alpha': 0.5}\n",
      "[16:17:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:17:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:17:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:18:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:18:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "Average expected test MSE: 7.4207154873361585\n",
      "True test error: 8.326421100468648\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor())),\n",
    "  ('regression', xgb.XGBRegressor())])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'feat_select__estimator__n_estimators' : [80, 100, 120],\n",
    "              'feat_select__estimator__min_samples_leaf' : [1, 2, 4, 5, 6],\n",
    "              'feat_select__threshold' : [-np.inf],\n",
    "              'feat_select__max_features' : [10, 20, 60, 70],\n",
    "              'regression__booster__alpha' : [0.05, 0.2, 0.5]\n",
    "              #'regression__booster__max_depth' : [3, 4, 5, 6, 7]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 13.702507670908801\n",
      "Selected hyperparameters: {'regression__alpha': 2}\n",
      "Split: 1\r",
      "Split: 2\r",
      "Split: 3\r",
      "Split: 4\r",
      "Split: 5\r\n",
      "Average expected test MSE: 13.702507670908798\n",
      "True test error: 13.869415734497567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.5s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('regression', Lasso())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'regression__alpha' : [1, 1.2, 1.4, 1.7, 1.9, 2, 2.3, 2.5, 3, 3.5, 4, 6],\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 13.702507670908801\n",
      "Selected hyperparameters: {'feat_select__estimator__min_samples_leaf': 1, 'feat_select__estimator__n_estimators': 80, 'feat_select__max_features': 10, 'feat_select__threshold': -inf, 'regression__alpha': 2}\n",
      "Split: 5\n",
      "Average expected test MSE: 13.702507670908798\n",
      "True test error: 13.869415734497567\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "                 ('feat_select', SelectFromModel(ExtraTreesRegressor())),\n",
    "  ('regression', Lasso())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'feat_select__estimator__n_estimators' : [80, 100],\n",
    "              'feat_select__estimator__min_samples_leaf' : [1, 2, 4],\n",
    "              'feat_select__threshold' : [-np.inf],\n",
    "              'feat_select__max_features' : [10, 20, 30, 70, 90, 110],\n",
    "              'regression__alpha' : [0.5, 1, 1.5, 2, 2.5, 3],\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectKBEST + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=-1)]: Done 603 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:   50.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:17:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean cross-validated score of the best estimator: 8.141871573760335\n",
      "Selected hyperparameters: {'feat_select__k': 10, 'feat_select__score_func': <function f_regression at 0x7fb656a33730>, 'regression__booster__alpha': 0, 'regression__booster__max_depth': 3}\n",
      "[12:17:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:11] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "Average expected test MSE: 8.141871573760339\n",
      "True test error: 8.18585807438065\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectKBest()),\n",
    "  ('regression', xgb.XGBRegressor())])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'feat_select__score_func' : [f_regression],\n",
    "            'feat_select__k' : [10, 30, 60, 100, 120, 160],\n",
    "              'regression__booster__alpha' : [0, 0.05, 0.1, 0.2, 0.6, 1],\n",
    "              'regression__booster__max_depth' : [3, 4, 5, 6, 7]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI + DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Age'\n",
    "# use all MRI high-level features, no DTI\n",
    "data = create_dataset_mri(SCORE = target, DTI = True)\n",
    "# for the moment, remove the diagnosis colums\n",
    "try:\n",
    "    data.drop(columns=['DX_01_Cat'], inplace=True)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    data.drop(columns=['DX_01_Sub'], inplace=True)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    data.drop(columns=['DX_01'], inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# labels and features\n",
    "y = data[target]\n",
    "X = data.drop([target, 'ID'], axis=1)\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectKBest + SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 524 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 774 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1124 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1574 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2124 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2774 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3524 tasks      | elapsed: 11.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4320 out of 4320 | elapsed: 13.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 8.875603040249226\n",
      "Selected hyperparameters: {'feat_select__k': 160, 'feat_select__score_func': <function mutual_info_regression at 0x7fb656a4d730>, 'imputation__strategy': 'median', 'regression__C': 0.2, 'regression__epsilon': 0.05, 'regression__kernel': 'rbf'}\n",
      "Split: 5\n",
      "Average expected test MSE: 8.851096243661612\n",
      "True test error: 8.842062973417255\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('imputation', SimpleImputer()), ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectKBest()),\n",
    "  ('regression', SVR())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'imputation__strategy' : ['mean', 'median', 'most_frequent'],\n",
    "            'regression__C' : [0.2, 0.5, 0.8, 1, 1.5, 2.5],\n",
    "            'regression__epsilon' : [0.05, 0.1, 0.3, 0.5],\n",
    "            'regression__kernel' : ['rbf'],\n",
    "            'feat_select__score_func' : [f_regression, mutual_info_regression],\n",
    "            'feat_select__k' : [10, 30, 80, 100, 120, 160]}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 720 candidates, totalling 3600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 13.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 26.6min\n",
      "[Parallel(n_jobs=-1)]: Done 3600 out of 3600 | elapsed: 30.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 7.630540341157975\n",
      "Selected hyperparameters: {'feat_select__estimator__n_estimators': 100, 'feat_select__max_features': 10, 'feat_select__threshold': -inf, 'imputation__strategy': 'median', 'regression__C': 0.3, 'regression__epsilon': 0.05, 'regression__kernel': 'rbf'}\n",
      "Split: 5\n",
      "Average expected test MSE: 7.378802196203989\n",
      "True test error: 7.147595633706364\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('imputation', SimpleImputer()), ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor(100))),\n",
    "  ('regression', SVR())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'imputation__strategy' : ['mean', 'median', 'most_frequent'],\n",
    "              'regression__C' : [0.3, 0.5, 0.8, 1, 1.5, 2],\n",
    "            'regression__epsilon' : [0.05, 0.1, 0.3, 0.5],\n",
    "            'regression__kernel' : ['rbf'],\n",
    "            'feat_select__estimator__n_estimators' : [100, 130],\n",
    "            'feat_select__threshold' : [-np.inf],\n",
    "            'feat_select__max_features' : [10, 30, 80, 100, 130]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4320 candidates, totalling 21600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed: 16.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3176 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4026 tasks      | elapsed: 27.0min\n",
      "[Parallel(n_jobs=-1)]: Done 4976 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6026 tasks      | elapsed: 36.2min\n",
      "[Parallel(n_jobs=-1)]: Done 7176 tasks      | elapsed: 42.4min\n",
      "[Parallel(n_jobs=-1)]: Done 8426 tasks      | elapsed: 46.2min\n",
      "[Parallel(n_jobs=-1)]: Done 9776 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done 11226 tasks      | elapsed: 56.1min\n",
      "[Parallel(n_jobs=-1)]: Done 12776 tasks      | elapsed: 60.8min\n",
      "[Parallel(n_jobs=-1)]: Done 14426 tasks      | elapsed: 66.8min\n",
      "[Parallel(n_jobs=-1)]: Done 16176 tasks      | elapsed: 71.7min\n",
      "[Parallel(n_jobs=-1)]: Done 18026 tasks      | elapsed: 77.9min\n",
      "[Parallel(n_jobs=-1)]: Done 19976 tasks      | elapsed: 82.7min\n",
      "[Parallel(n_jobs=-1)]: Done 21600 out of 21600 | elapsed: 87.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:13:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean cross-validated score of the best estimator: 8.166805203413324\n",
      "Selected hyperparameters: {'feat_select__estimator__min_samples_leaf': 2, 'feat_select__estimator__n_estimators': 80, 'feat_select__max_features': 10, 'feat_select__threshold': -inf, 'imputation__strategy': 'median', 'regression__booster__alpha': 0.2, 'regression__booster__max_depth': 6}\n",
      "[20:13:45] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:13:47] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:13:48] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:13:49] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[20:13:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "Average expected test MSE: 7.970171129707256\n",
      "True test error: 7.526156153724901\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('imputation', SimpleImputer()), ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor())),\n",
    "  ('regression', xgb.XGBRegressor())])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'imputation__strategy' : ['mean', 'median', 'most_frequent'],\n",
    "              'feat_select__estimator__n_estimators' : [80, 100],\n",
    "              'feat_select__estimator__min_samples_leaf' : [1, 2, 4, 5, 6, 8],\n",
    "              'feat_select__threshold' : [-np.inf],\n",
    "              'feat_select__max_features' : [10, 20, 50, 70, 100, 140],\n",
    "              'regression__booster__alpha' : [0, 0.05, 0.1, 0.2],\n",
    "              'regression__booster__max_depth' : [3, 4, 5, 6, 7]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('imputation', SimpleImputer()), ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor())),\n",
    "  ('regression', RandomForestRegressor())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'imputation__strategy' : ['mean', 'median', 'most_frequent'],\n",
    "              'feat_select__estimator__n_estimators' : [50, 100],\n",
    "              'feat_select__estimator__min_samples_leaf' : [1, 5, 8],\n",
    "            'feat_select__threshold' : [-np.inf],\n",
    "            'feat_select__max_features' : [100],\n",
    "            'regression__max_depth' : [2, 3, 6, 8],\n",
    "            'regression__min_samples_leaf' : [1, 3, 5, 8]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dslab",
   "language": "python",
   "name": "dslab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
