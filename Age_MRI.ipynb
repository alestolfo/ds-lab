{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age prediction from MRI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import visualize, create_dataset_age, create_dataset_mri, cv\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import xgboost as xgb\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Age'\n",
    "# use all MRI high-level features, no DTI\n",
    "data = create_dataset_mri(SCORE = target)\n",
    "# remove the diagnosis colums\n",
    "data.drop(columns=['DX_01_Cat', 'DX_01', 'DX_01_Sub'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = pd.read_csv('data/test_indices.csv')\n",
    "# Separate test and train set\n",
    "data_test = pd.merge(data, test_indices, on='ID', how='inner')\n",
    "data_train = data.loc[~data['ID'].isin(list((set(test_indices['ID']))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels and features\n",
    "y_train = data_train[target]\n",
    "X_train = data_train.drop([target, 'ID'], axis=1)\n",
    "y_test = data_test[target]\n",
    "X_test = data_test.drop([target, 'ID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix a baseline (mean age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_age = 10.769986650924025\n",
      "baseline_MSE = 13.613808757061083\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "mean = np.mean(y_train)\n",
    "print('mean_age = {}'.format(mean))\n",
    "baseline_MSE = sum((mean - y_train)**2)/len(y_train)\n",
    "print('baseline_MSE = {}'.format(baseline_MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore different regressors and feature selection procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR with no feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    4.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 6.709482422552265\n",
      "Selected hyperparameters: {'regression__C': 0.5, 'regression__epsilon': 0.7, 'regression__kernel': 'rbf'}\n",
      "Split: 5\n",
      "Average expected test MSE: 6.709482422552265\n",
      "True test error: 5.445450380644605\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('regression', SVR())])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'regression__C' : [0.5, 1],\n",
    "            'regression__epsilon' : [0.1, 0.5, 0.7],\n",
    "            'regression__kernel' : ['rbf']}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectKBest + SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done  52 out of  75 | elapsed:    0.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 7.7755761723861525\n",
      "Selected hyperparameters: {'feat_select__k': 10, 'feat_select__score_func': <function f_regression at 0x7fa759aba730>, 'regression__C': 1, 'regression__epsilon': 0.1, 'regression__kernel': 'rbf'}\n",
      "Split: 1\r",
      "Split: 2\r",
      "Split: 3\r",
      "Split: 4\r",
      "Split: 5\r\n",
      "Average expected test MSE: 7.775576172386151\n",
      "True test error: 6.210321452613395\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectKBest()),\n",
    "  ('regression', SVR())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'regression__C' : [1],\n",
    "            'regression__epsilon' : [0.1, 0.5, 0.7],\n",
    "            'regression__kernel' : ['rbf'],\n",
    "            'feat_select__score_func' : [f_regression],\n",
    "            'feat_select__k' : [10, 20, 40, 80, 95]}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   33.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 6.1947240734490405\n",
      "Selected hyperparameters: {'feat_select__estimator__n_estimators': 100, 'regression__C': 0.3, 'regression__epsilon': 0.05, 'regression__kernel': 'rbf'}\n",
      "Split: 5\n",
      "Average expected test MSE: 6.120492336319738\n",
      "True test error: 5.138094886215391\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor(100))),\n",
    "  ('regression', SVR())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'regression__C' : [0.3, 1, 1.5],\n",
    "            'regression__epsilon' : [0.05, 0.1, 0.5],\n",
    "            'regression__kernel' : ['rbf'],\n",
    "            'feat_select__estimator__n_estimators' : [100],}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   36.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 6.2497726989661135\n",
      "Selected hyperparameters: {'feat_select__estimator__n_estimators': 100, 'regression__C': 0.3, 'regression__epsilon': 0.1, 'regression__kernel': 'rbf'}\n",
      "Split: 5\n",
      "Average expected test MSE: 6.1740307610545235\n",
      "True test error: 5.176076343417024\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor(100))),\n",
    "  ('regression', SVR())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'regression__C' : [0.3, 1, 1.5],\n",
    "            'regression__epsilon' : [0.05, 0.1, 0.5],\n",
    "            'regression__kernel' : ['rbf'],\n",
    "            'feat_select__estimator__n_estimators' : [100]}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 8.617530716446783\n",
      "Selected hyperparameters: {'regression__max_depth': 2, 'regression__min_samples_leaf': 1}\n",
      "Split: 5\n",
      "Average expected test MSE: 8.468681272169247\n",
      "True test error: 7.220620939182452\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('regression', RandomForestRegressor())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'regression__max_depth' : [2, 3, 6, 12],\n",
    "            'regression__min_samples_leaf' : [1, 3, 5, 8]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lh_G.S_frontomargin_thickness', 'lh_G.S_occipital_inf_thickness',\n",
       "       'lh_G.S_paracentral_thickness', 'lh_G.S_subcentral_thickness',\n",
       "       'lh_G.S_transv_frontopol_thickness', 'lh_G.S_cingul.Ant_thickness',\n",
       "       'lh_G.S_cingul.Mid.Ant_thickness', 'lh_G.S_cingul.Mid.Post_thickness',\n",
       "       'lh_G_cingul.Post.dorsal_thickness',\n",
       "       'lh_G_cingul.Post.ventral_thickness',\n",
       "       ...\n",
       "       'rh_rostralmiddlefrontal_volume', 'rh_superiorfrontal_volume',\n",
       "       'rh_superiorparietal_volume', 'rh_superiortemporal_volume',\n",
       "       'rh_supramarginal_volume', 'rh_frontalpole_volume',\n",
       "       'rh_temporalpole_volume', 'rh_transversetemporal_volume',\n",
       "       'rh_insula_volume', 'GlobalCorticalThickness'],\n",
       "      dtype='object', length=369)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "weights = model.best_estimator_.steps[1][1].feature_importances_\n",
    "kth_weight = np.sort(weights)[::-1][k]\n",
    "k_most_relevant = column_names[weights>= kth_weight]\n",
    "k_most_relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 225 out of 225 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:32:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean cross-validated score of the best estimator: 5.526072228192527\n",
      "Selected hyperparameters: {'feat_select__estimator__min_samples_leaf': 1, 'feat_select__estimator__n_estimators': 80, 'regression__booster__alpha': 0.05}\n",
      "[15:32:24] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:32:27] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:32:30] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:32:33] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:32:35] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "Average expected test MSE: 5.5032408918160165\n",
      "True test error: 4.597963756967613\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor())),\n",
    "  ('regression', xgb.XGBRegressor())])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'feat_select__estimator__n_estimators' : [80, 100, 120],\n",
    "              'feat_select__estimator__min_samples_leaf' : [1, 2, 4, 5, 6],\n",
    "              'regression__booster__alpha' : [0.05, 0.2, 0.5]\n",
    "              #'regression__booster__max_depth' : [3, 4, 5, 6, 7]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 13.739976826962371\n",
      "Selected hyperparameters: {'regression__alpha': 1.9}\n",
      "Split: 1\r",
      "Split: 2\r",
      "Split: 3\r",
      "Split: 4\r",
      "Split: 5\r\n",
      "Average expected test MSE: 13.739976826962373\n",
      "True test error: 14.3209324643211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('regression', Lasso())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'regression__alpha' : [1, 1.2, 1.4, 1.7, 1.9, 2, 2.3, 2.5, 3, 3.5, 4, 6],\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  8.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 13.739976826962371\n",
      "Selected hyperparameters: {'feat_select__estimator__min_samples_leaf': 1, 'feat_select__estimator__n_estimators': 80, 'feat_select__max_features': 10, 'feat_select__threshold': -inf, 'regression__alpha': 2}\n",
      "Split: 5\n",
      "Average expected test MSE: 13.739976826962373\n",
      "True test error: 14.3209324643211\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "                 ('feat_select', SelectFromModel(ExtraTreesRegressor())),\n",
    "  ('regression', Lasso())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'feat_select__estimator__n_estimators' : [80, 100],\n",
    "              'feat_select__estimator__min_samples_leaf' : [1, 2, 4],\n",
    "              'feat_select__threshold' : [-np.inf],\n",
    "              'feat_select__max_features' : [10, 20, 30, 70, 90, 110],\n",
    "              'regression__alpha' : [0.5, 1, 1.5, 2, 2.5, 3],\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectKBEST + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 180 candidates, totalling 900 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 601 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 900 out of 900 | elapsed:   57.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:42:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean cross-validated score of the best estimator: 8.285576482110569\n",
      "Selected hyperparameters: {'feat_select__k': 10, 'feat_select__score_func': <function f_regression at 0x7fa759aba730>, 'regression__booster__alpha': 0, 'regression__booster__max_depth': 3}\n",
      "[15:42:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:42:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:42:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:42:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[15:42:36] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "Average expected test MSE: 8.285576482110567\n",
      "True test error: 6.416581002334373\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectKBest()),\n",
    "  ('regression', xgb.XGBRegressor())])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'feat_select__score_func' : [f_regression],\n",
    "            'feat_select__k' : [10, 30, 60, 100, 120, 160],\n",
    "              'regression__booster__alpha' : [0, 0.05, 0.1, 0.2, 0.6, 1],\n",
    "              'regression__booster__max_depth' : [3, 4, 5, 6, 7]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI + DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Age'\n",
    "# use all MRI high-level features, no DTI\n",
    "data = create_dataset_mri(SCORE = target, DTI = True)\n",
    "# for the moment, remove the diagnosis colums\n",
    "try:\n",
    "    data.drop(columns=['DX_01_Cat'], inplace=True)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    data.drop(columns=['DX_01_Sub'], inplace=True)\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    data.drop(columns=['DX_01'], inplace=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# labels and features\n",
    "y = data[target]\n",
    "X = data.drop([target, 'ID'], axis=1)\n",
    "# split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SelectKBest + SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 524 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 774 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1124 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1574 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 2124 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2774 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3524 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4320 out of 4320 | elapsed: 14.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 8.887435232673859\n",
      "Selected hyperparameters: {'feat_select__k': 160, 'feat_select__score_func': <function mutual_info_regression at 0x7fa759a52730>, 'imputation__strategy': 'mean', 'regression__C': 0.2, 'regression__epsilon': 0.05, 'regression__kernel': 'rbf'}\n",
      "Split: 5\n",
      "Average expected test MSE: 8.878170274415526\n",
      "True test error: 8.785654315666354\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('imputation', SimpleImputer()), ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectKBest()),\n",
    "  ('regression', SVR())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'imputation__strategy' : ['mean', 'median', 'most_frequent'],\n",
    "            'regression__C' : [0.2, 0.5, 0.8, 1, 1.5, 2.5],\n",
    "            'regression__epsilon' : [0.05, 0.1, 0.3, 0.5],\n",
    "            'regression__kernel' : ['rbf'],\n",
    "            'feat_select__score_func' : [f_regression, mutual_info_regression],\n",
    "            'feat_select__k' : [10, 30, 80, 100, 120, 160]}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 360 out of 360 | elapsed:  2.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 6.911194891050914\n",
      "Selected hyperparameters: {'feat_select__estimator__n_estimators': 100, 'imputation__strategy': 'mean', 'regression__C': 0.3, 'regression__epsilon': 0.1, 'regression__kernel': 'rbf'}\n",
      "Split: 5\n",
      "Average expected test MSE: 6.858542234247179\n",
      "True test error: 6.398964606842202\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('imputation', SimpleImputer()), ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor(100))),\n",
    "  ('regression', SVR())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'imputation__strategy' : ['mean', 'median', 'most_frequent'],\n",
    "              'regression__C' : [0.3, 0.5, 0.8, 1, 1.5, 2],\n",
    "            'regression__epsilon' : [0.05, 0.1, 0.3, 0.5],\n",
    "            'regression__kernel' : ['rbf'],\n",
    "            'feat_select__estimator__n_estimators' : [100],\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 135 candidates, totalling 675 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 675 out of 675 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:03:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Mean cross-validated score of the best estimator: 5.969363604014561\n",
      "Selected hyperparameters: {'feat_select__estimator__min_samples_leaf': 6, 'feat_select__estimator__n_estimators': 120, 'imputation__strategy': 'mean', 'regression__booster__alpha': 0.5}\n",
      "[16:03:22] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:03:23] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:03:24] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:03:25] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:03:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost_1566327313563/work/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "\n",
      "Average expected test MSE: 5.798785211840278\n",
      "True test error: 5.9898162720166725\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('imputation', SimpleImputer()), ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor())),\n",
    "  ('regression', xgb.XGBRegressor())])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'imputation__strategy' : ['mean', 'median', 'most_frequent'],\n",
    "              'feat_select__estimator__n_estimators' : [80, 100, 120],\n",
    "              'feat_select__estimator__min_samples_leaf' : [1, 2, 4, 5, 6],\n",
    "              'regression__booster__alpha' : [0.05, 0.2, 0.5]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   43.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1440 out of 1440 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best estimator: 8.399436322812138\n",
      "Selected hyperparameters: {'feat_select__estimator__min_samples_leaf': 8, 'feat_select__estimator__n_estimators': 100, 'imputation__strategy': 'most_frequent', 'regression__max_depth': 2, 'regression__min_samples_leaf': 3}\n",
      "Split: 5\n",
      "Average expected test MSE: 8.397745416653773\n",
      "True test error: 8.253370360974069\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('imputation', SimpleImputer()), ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor())),\n",
    "  ('regression', RandomForestRegressor())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'imputation__strategy' : ['mean', 'median', 'most_frequent'],\n",
    "              'feat_select__estimator__n_estimators' : [50, 100],\n",
    "              'feat_select__estimator__min_samples_leaf' : [1, 5, 8],\n",
    "            'regression__max_depth' : [2, 3, 6, 8],\n",
    "            'regression__min_samples_leaf' : [1, 3, 5, 8]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = make_scorer(mean_squared_error), cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "# inner CV (model selection)\n",
    "model = model.fit(X_train, y_train)\n",
    "# see what has been chosen\n",
    "print('Mean cross-validated score of the best estimator: {}'.format(model.best_score_)  )      \n",
    "print('Selected hyperparameters: {}'.format(model.best_params_) )\n",
    "# outer CV (model evaluation)\n",
    "estimated_test_error = cv(model.best_estimator_, data=X_train, labels=y_train, n_splits=5)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "# effective test MSE\n",
    "y_pred = model.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dslab",
   "language": "python",
   "name": "dslab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
