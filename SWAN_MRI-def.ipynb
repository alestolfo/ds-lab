{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age prediction from eeg features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import visualize, create_dataset_age, create_dataset_mri, cv\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alestolfo/anaconda2/envs/ds-lab/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3183: DtypeWarning: Columns (50,78,80,91,92,93,94,95,105,106,107,108,109,119,120,121,123,133,134,135,137,276,291,292,295,296,297,300,301,302,305,306,307) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (yield from self.run_code(code, result)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1146, 371)\n",
      "(1047, 371)\n"
     ]
    }
   ],
   "source": [
    "target = 'SWAN_Avg'\n",
    "# use average and clusters eeg features\n",
    "# consider all the patients\n",
    "data = create_dataset_mri(SCORE = target)\n",
    "# remove the diagnosis colums\n",
    "data.drop(columns=['DX_01_Cat', 'DX_01_Sub', 'DX_01'], inplace=True)\n",
    "data = data.rename(columns={'id':'ID'})\n",
    "\n",
    "print(data.shape)\n",
    "data.dropna(axis=0, inplace=True, subset=[target])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = pd.read_csv('data/test_IDS.csv')\n",
    "# Separate test and train set\n",
    "data_test = pd.merge(data, test_indices, on='ID', how='inner')\n",
    "data_train = data.loc[~data['ID'].isin(list((set(test_indices['ID']))))]\n",
    "# labels and features\n",
    "y_train = data_train[target]\n",
    "X_train = data_train.drop([target, 'ID'], axis=1)\n",
    "y_test = data_test[target]\n",
    "X_test = data_test.drop([target, 'ID'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix a baseline (mean age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_age = 0.4441461899141631\n",
      "baseline_MSE = 1.0989534552081381\n"
     ]
    }
   ],
   "source": [
    "# Baseline\n",
    "mean = np.mean(y_train)\n",
    "print('mean_age = {}'.format(mean))\n",
    "baseline_MSE = sum((mean - y_train)**2)/len(y_train)\n",
    "print('baseline_MSE = {}'.format(baseline_MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test error: 0.9636393545352753\n"
     ]
    }
   ],
   "source": [
    "print('Baseline test error: {}'.format(sum((mean - y_test)**2)/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore different regressors and feature selection procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use AVERAGE features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExtraTrees + SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 1\r",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 13.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 2\r",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 11.3min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 3\r",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 11.9min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 12.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 4\r",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 12.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 5\r",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 11.4min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 12.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average expected test MSE: 1.1155944280738175\n",
      "\n",
      "Average expected test R^2: -0.020777353896919194\n",
      "\n",
      "Average expected test mae: 0.8078557383013981\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 14.4min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 15.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected hyperparameters: {'feat_select__estimator__n_estimators': 100, 'feat_select__max_features': 50, 'feat_select__threshold': -inf, 'imputation__strategy': 'mean', 'regression__C': 0.5, 'regression__epsilon': 0.1, 'regression__kernel': 'rbf'}\n",
      "True test error: 0.9545700643687751\n",
      "Test r2: 0.006249807447861744\n",
      "Test mae: 0.7582741234035589\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('imputation', SimpleImputer()), ('scaling', StandardScaler()),\n",
    "  ('feat_select', SelectFromModel(ExtraTreesRegressor(100))),\n",
    "  ('regression', SVR())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'imputation__strategy' : ['mean', 'median'],\n",
    "            'regression__C' : [0.5, 0.8, 1, 2],\n",
    "            'regression__epsilon' : [0.05, 0.1, 0.5],\n",
    "            'regression__kernel' : ['rbf'],\n",
    "            'feat_select__estimator__n_estimators' : [100],\n",
    "            'feat_select__threshold' : [-np.inf],\n",
    "            'feat_select__max_features' : [10, 20, 50, 60]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring =  'neg_mean_squared_error', cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "\n",
    "# outer CV (model evaluation)\n",
    "(estimated_test_error, r2, mae) = cv(model, data=X_train, labels=y_train, n_splits=5, want_r2 = True, want_mae = True)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "print('\\nAverage expected test R^2: {}'.format(np.mean(r2)))\n",
    "print('\\nAverage expected test mae: {}'.format(np.mean(mae)))\n",
    "# effective test MSE\n",
    "model_fitted = model.fit(X_train, y_train)\n",
    "# see what has been chosen    \n",
    "print('Selected hyperparameters: {}'.format(model_fitted.best_params_) )\n",
    "y_pred = model_fitted.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))\n",
    "print('Test r2: {}'.format(r2_score(y_true= y_test, y_pred = y_pred)))\n",
    "print('Test mae: {}'.format(mean_absolute_error(y_true= y_test, y_pred = y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 1\r",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   43.4s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 2\r",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 3\r",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 4\r",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 5\r",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average expected test MSE: 1.1605145235126204\n",
      "\n",
      "Average expected test r2: -0.0724811477686003\n",
      "\n",
      "Average expected test mae: 0.8339342304264219\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   45.8s\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected hyperparameters: {'imputation__strategy': 'mean', 'regression__booster__alpha': 0, 'regression__booster__max_depth': 3}\n",
      "True test error: 1.0328052911497267\n",
      "Test r2: -0.07519656781568895\n",
      "Test mae: 0.781719940752444\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([ ('imputation', SimpleImputer()), ('scaling', StandardScaler()),\n",
    "  ('regression', xgb.XGBRegressor())])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'imputation__strategy' : ['mean', 'median', 'most_frequent'],\n",
    "              'regression__booster__alpha' : [0, 0.05, 0.1, 0.2],\n",
    "              'regression__booster__max_depth' : [3, 4, 6]\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring =  'neg_mean_squared_error', cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "\n",
    "# Nested CV\n",
    "(estimated_test_error, r2, mae) = cv(model, data=X_train, labels=y_train, n_splits=5, want_r2 = True, want_mae = True)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "print('\\nAverage expected test r2: {}'.format(np.mean(r2)))\n",
    "print('\\nAverage expected test mae: {}'.format(np.mean(mae)))\n",
    "# effective test MSE\n",
    "model_fitted = model.fit(X_train, y_train)\n",
    "# see what has been chosen   \n",
    "print('Selected hyperparameters: {}'.format(model_fitted.best_params_) )\n",
    "y_pred = model_fitted.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))\n",
    "print('Test r2: {}'.format(r2_score(y_true= y_test, y_pred = y_pred)))\n",
    "print('Test mae: {}'.format(mean_absolute_error(y_true= y_test, y_pred = y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 1\r",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 2\r",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 3\r",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.3min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 4\r",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 5\r",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average expected test MSE: 1.1003068880673905\n",
      "\n",
      "Average expected test r2: -0.004502408769313471\n",
      "\n",
      "Average expected test mae: 0.7962430920258633\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 173 out of 180 | elapsed:  1.4min remaining:    3.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected hyperparameters: {'imputation__strategy': 'mean', 'regression__alpha': 1}\n",
      "True test error: 0.9636393545352754\n",
      "Test r2: -0.0031917298323069776\n",
      "Test mae: 0.7545917374790073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('imputation', SimpleImputer()), ('scaling', StandardScaler()),\n",
    "  ('regression', Lasso())\n",
    "])\n",
    "# Prepare sets of parameters for gridsearch\n",
    "parameters = {'imputation__strategy' : ['mean', 'median', 'most_frequent'],\n",
    "              'regression__alpha' : [1, 1.2, 1.4, 1.7, 1.9, 2, 2.3, 2.5, 3, 3.5, 4, 6],\n",
    "}\n",
    "model = GridSearchCV(estimator=pipe, param_grid=parameters, scoring = 'neg_mean_squared_error', cv=5,\n",
    "                   iid=False, n_jobs=-1, verbose = 1)\n",
    "\n",
    "# outer CV (model evaluation)\n",
    "(estimated_test_error, r2, mae) = cv(model, data=X_train, labels=y_train, n_splits=5, want_r2=True, want_mae = True)\n",
    "print('\\nAverage expected test MSE: {}'.format(np.mean(estimated_test_error)))\n",
    "print('\\nAverage expected test r2: {}'.format(np.mean(r2)))\n",
    "print('\\nAverage expected test mae: {}'.format(np.mean(mae)))\n",
    "# effective test MSE\n",
    "model_fitted = model.fit(X_train, y_train)\n",
    "# see what has been chosen     \n",
    "print('Selected hyperparameters: {}'.format(model_fitted.best_params_) )\n",
    "y_pred = model_fitted.best_estimator_.predict(X_test)\n",
    "print('True test error: {}'.format(mean_squared_error(y_pred, y_test)))\n",
    "print('Test r2: {}'.format(r2_score(y_true= y_test, y_pred = y_pred)))\n",
    "print('Test mae: {}'.format(mean_absolute_error(y_true= y_test, y_pred = y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (ds-lab)",
   "language": "python",
   "name": "ds-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
